{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da0d68-211d-4d32-80d7-3f3ca4437c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./venv/lib/python3.13/site-packages (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.13/site-packages (from accelerate) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.13/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.13/site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in ./venv/lib/python3.13/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./venv/lib/python3.13/site-packages (from accelerate) (2.9.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./venv/lib/python3.13/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.13/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./venv/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets trl torch pandas scikit-learn accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ee7dc",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c522aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./data/Tweets.csv')\n",
    "\n",
    "# 1. Select relevant columns\n",
    "df = df[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d964ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airline_sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "labels",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b84cf90a-ba9f-4ee3-9cf6-271549d4e31f",
       "rows": [
        [
         "0",
         "What  said.",
         "neutral",
         "1"
        ],
        [
         "1",
         "plus you've added commercials to the experience... tacky.",
         "positive",
         "2"
        ],
        [
         "2",
         "I didn't today... Must mean I need to take another trip!",
         "neutral",
         "1"
        ],
        [
         "3",
         "it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse",
         "negative",
         "0"
        ],
        [
         "4",
         "and it's a really big bad thing about it",
         "negative",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What  said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus you've added commercials to the experienc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I didn't today... Must mean I need to take ano...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it's really aggressive to blast obnoxious \"ent...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and it's a really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  labels\n",
       "0                                        What  said.           neutral       1\n",
       "1  plus you've added commercials to the experienc...          positive       2\n",
       "2  I didn't today... Must mean I need to take ano...           neutral       1\n",
       "3  it's really aggressive to blast obnoxious \"ent...          negative       0\n",
       "4           and it's a really big bad thing about it          negative       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2518637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Map sentiment labels to integers\n",
    "# We'll use: 0 = negative, 1 = neutral, 2 = positive\n",
    "label_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "df['labels'] = df['airline_sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70642cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clean the text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove @mentions\n",
    "    text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "    text = text.strip() # Remove leading/trailing whitespace\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Drop rows where sentiment mapping might have failed (if any)\n",
    "df = df.dropna(subset=['labels'])\n",
    "df['labels'] = df['labels'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14500979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split the data into training and testing sets (80% train, 20% test)\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['labels']  # Important for imbalanced datasets!\n",
    ")\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Training dataset shape: {train_df.shape}\")\n",
    "print(f\"Testing dataset shape: {test_df.shape}\")\n",
    "\n",
    "print(\"\\nTraining set sentiment distribution:\")\n",
    "print(train_df['airline_sentiment'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTesting set sentiment distribution:\")\n",
    "print(test_df['airline_sentiment'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a36645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (14640, 3)\n",
      "Training dataset shape: (11712, 3)\n",
      "Testing dataset shape: (2928, 3)\n",
      "\n",
      "Training set sentiment distribution:\n",
      "airline_sentiment\n",
      "negative    0.626964\n",
      "neutral     0.211663\n",
      "positive    0.161373\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Testing set sentiment distribution:\n",
      "airline_sentiment\n",
      "negative    0.626708\n",
      "neutral     0.211749\n",
      "positive    0.161544\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "'train_processed.csv' and 'test_processed.csv' have been created.\n"
     ]
    }
   ],
   "source": [
    "# 5. Save the processed data to files for the next step\n",
    "train_df.to_csv('./data/train_processed.csv', index=False)\n",
    "test_df.to_csv('./data/test_processed.csv', index=False)\n",
    "\n",
    "print(\"\\n'train_processed.csv' and 'test_processed.csv' have been created in the './data/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff57792d",
   "metadata": {},
   "source": [
    "## Create the Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc76dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train dataset with 11712 examples.\n",
      "Loaded test dataset with 2928 examples.\n",
      "\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 11712/11712 [00:00<00:00, 21357.26 examples/s]\n",
      "Map: 100%|██████████| 2928/2928 [00:00<00:00, 21830.85 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/ns/mp2t798n28l81cvv4hpmdpyr0000gn/T/ipykernel_21936/800203132.py:85: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n",
      "\n",
      "Loading model: distilbert-base-uncased\n",
      "Configuring Trainer...\n",
      "\n",
      "Starting baseline model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chani/Projects/trl_Sentiment_Analysis_with_Reinforcement_Learning/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2196' max='2196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2196/2196 28:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.459700</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>0.820697</td>\n",
       "      <td>0.818803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>0.460359</td>\n",
       "      <td>0.839822</td>\n",
       "      <td>0.836332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.602882</td>\n",
       "      <td>0.840505</td>\n",
       "      <td>0.839446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chani/Projects/trl_Sentiment_Analysis_with_Reinforcement_Learning/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/Users/chani/Projects/trl_Sentiment_Analysis_with_Reinforcement_Learning/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete. Evaluating model on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chani/Projects/trl_Sentiment_Analysis_with_Reinforcement_Learning/venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Baseline Model Evaluation Results ---\n",
      "Accuracy: 0.8405\n",
      "F1-score (Weighted): 0.8394\n",
      "{'eval_loss': 0.602882444858551, 'eval_accuracy': 0.8405054644808743, 'eval_f1': 0.8394463938652994, 'eval_runtime': 35.2944, 'eval_samples_per_second': 82.959, 'eval_steps_per_second': 1.303, 'epoch': 3.0}\n",
      "\n",
      "Saving final model to './final-baseline-model'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./final-baseline-model/tokenizer_config.json',\n",
       " './final-baseline-model/special_tokens_map.json',\n",
       " './final-baseline-model/vocab.txt',\n",
       " './final-baseline-model/added_tokens.json',\n",
       " './final-baseline-model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import torch  \n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# Auto-detect GPU (CUDA or Apple Silicon 'mps') ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU: Using CUDA (NVIDIA GPU)\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"GPU: Using MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU: Using CPU\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Load Preprocessed Data ---\n",
    "try:\n",
    "    train_df = pd.read_csv('./data/train_processed.csv')\n",
    "    test_df = pd.read_csv('./data/test_processed.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train_processed.csv' or 'test_processed.csv' not found.\")\n",
    "    print(\"Please ensure Step 2 ran successfully.\")\n",
    "    exit()\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "print(f\"Loaded train dataset with {len(train_dataset)} examples.\")\n",
    "print(f\"Loaded test dataset with {len(test_dataset)} examples.\")\n",
    "\n",
    "# --- 2. Load Tokenizer and Tokenize Data ---\n",
    "MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "print(\"\\nTokenizing datasets...\")\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns(['text', 'airline_sentiment'])\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns(['text', 'airline_sentiment'])\n",
    "print(\"Tokenization complete.\")\n",
    "\n",
    "# --- 3. Load Pre-trained Model ---\n",
    "label_map = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "id2label = {id: label for id, label in label_map.items()}\n",
    "label2id = {label: id for id, label in label_map.items()}\n",
    "\n",
    "print(f\"\\nLoading model: {MODEL_CHECKPOINT}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT,\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)  \n",
    "\n",
    "# --- 4. Define Evaluation Metrics ---\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Logits might be on GPU, move to CPU for numpy\n",
    "    predictions = np.argmax(logits.cpu(), axis=-1)\n",
    "    labels = labels.cpu()\n",
    "    \n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "# --- 5. Set Up the Trainer ---\n",
    "print(\"Configuring Trainer...\")\n",
    "\n",
    "# Note: We fixed 'eval_strategy' in our previous step\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results-baseline\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,      # Batch size per device\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs-baseline',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# --- 6. Run Training & Evaluation ---\n",
    "print(\"\\nStarting baseline model training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nTraining complete. Evaluating model on the test set...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\n--- Baseline Model Evaluation Results ---\")\n",
    "print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"F1-score (Weighted): {eval_results['eval_f1']:.4f}\")\n",
    "print(eval_results)\n",
    "\n",
    "# Save your final model and tokenizer\n",
    "print(\"\\nSaving final model to './final-baseline-model'\")\n",
    "trainer.save_model(\"./final-baseline-model\")\n",
    "tokenizer.save_pretrained(\"./final-baseline-model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
